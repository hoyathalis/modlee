{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqFRMehQbTaS"
      },
      "source": [
        "# **Image Embeddings With Tabular Classification Model**\n",
        "\n",
        "In this tutorial, we will walk through the process of building an image classifier using embeddings from a pre-trained ResNet model combined with a custom Multi-Layer Perceptron (MLP). We'll train the MLP on embeddings extracted from ResNet, which will handle feature extraction from the CIFAR-10 dataset.\n",
        "\n",
        "## Tips\n",
        "For best performance, ensure that the runtime is set to use a GPU (`Runtime > Change runtime type > T4 GPU`).\n",
        "\n",
        "## Help & Questions\n",
        "\n",
        "If you have any questions, please reachout on our [Discord](https://discord.gg/dncQwFdN9m).\n",
        "\n",
        "You can also use our [documenation](https://docs.modlee.ai/README.html) as a reference for using our package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_xOi5vidByI"
      },
      "source": [
        "\n",
        "## Step 1: Environment Setup\n",
        "\n",
        "First, we need to make sure that we have the necessary packages installed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd8WWB6TdHEU"
      },
      "source": [
        "## Step 2: Importing Libraries\n",
        "\n",
        "In this section, we import the necessary libraries from `PyTorch` and `Torchvision`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install modlee torch torchvision pytorch-lightning torchtext==0.18.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V769goTfOfQA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchvision import datasets, models, transforms\n",
        "import modlee\n",
        "from torch.utils.data import DataLoader, Subset, random_split, TensorDataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfRebHJd4lef"
      },
      "source": [
        "Now we will set our Modlee API key and initialize the Modlee package.\n",
        "Make sure that you have a Modlee account and an API key [from the dashboard](https://www.dashboard.modlee.ai/).\n",
        "Replace `replace-with-your-api-key` with your API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p1gJu_bH4nwc"
      },
      "outputs": [],
      "source": [
        "# Set the API key to an environment variable,\n",
        "# to simulate setting this in your shell profile\n",
        "os.environ['MODLEE_API_KEY'] = \"replace-with-your-api-key\"\n",
        "modlee.init(api_key=os.environ['MODLEE_API_KEY'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blQojQsQhZL1"
      },
      "source": [
        "## Step 3: Data Preprocessing and Augmentation\n",
        "Next, we define a sequence of transformations to preprocess the images. These transformations help in data augmentation by introducing randomness into the dataset (such as horizontal flips and random cropping), making the model more robust to variations in the input data. Images are resized to (224, 224) to match the input size required by the pre-trained `ResNet-50` model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f5M2qaB-UAiG"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    # Randomly flip the image horizontally with a probability of 0.5\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "\n",
        "    # Randomly crop the image to 32x32 pixels with a padding of 4 pixels\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "\n",
        "    # Resize the image to 224x224 pixels to match the input size expected by ResNet-50\n",
        "    transforms.Resize((224, 224)),\n",
        "\n",
        "    # Convert the image to a PyTorch tensor\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    # Normalize the image with mean and standard deviation for each channel\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9eX3QaDlqle"
      },
      "source": [
        "## Step 4: Loading and Splitting the Dataset\n",
        "We load the `CIFAR-10` dataset, which consists of 60,000 images belonging to 10 different classes. We then create a subset of 1,000 images for faster experimentation and split it into training (80%) and validation (20%) datasets using `random_split`. This ensures that part of the data is held out for evaluation during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVit9uTlhdiS",
        "outputId": "aac51bec-7408-4a5c-d70a-e7c06fbdd5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load the CIFAR-10 dataset with the specified transformations\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Create a subset of the dataset for quicker experimentation\n",
        "subset_size = 1000\n",
        "indices = list(range(subset_size))\n",
        "subset_dataset = Subset(train_dataset, indices)\n",
        "\n",
        "# Split the subset into training and validation sets\n",
        "train_size = int(0.8 * len(subset_dataset))\n",
        "val_size = len(subset_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(subset_dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRQvz9hwmCTz"
      },
      "source": [
        "## Step 5: Creating DataLoaders for Batch Processing\n",
        "\n",
        "We define `DataLoaders` for both the training and validation datasets, setting the batch size to 64. `DataLoaders` are responsible for loading the data in batches, which is crucial for efficient training of deep learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LeTffYR-loyu"
      },
      "outputs": [],
      "source": [
        "# Create a DataLoader for the training dataset with shuffling enabled\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Create a DataLoader for the validation dataset without shuffling\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxYHvo1zmZyy"
      },
      "source": [
        "## Step 6: Loading a Pre-Trained ResNet-50 Model\n",
        "\n",
        "We load a pre-trained `ResNet-50` model from `torchvision.models` and modify it to output image embeddings instead of predictions by removing its fully connected (classification) layer. This allows us to use `ResNet` as a feature extractor, providing input features for our custom classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW7Ql3CtUBxP",
        "outputId": "c412dcec-accd-44c9-a25e-1d6c8c3e97e3"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained ResNet-50 model\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "# Remove the final fully connected layer to get feature embeddings\n",
        "resnet = nn.Sequential(*list(resnet.children())[:-1]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U_OASBYmmUG"
      },
      "source": [
        "## Step 7: Defining a Custom Multi-Layer Perceptron (MLP) Classifier\n",
        "\n",
        "We define a custom Multi-Layer Perceptron (MLP) classifier using fully connected layers, batch normalization, and dropout for regularization. The MLP receives the embeddings from `ResNet` as input and outputs class probabilities for the 10 `CIFAR-10` classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Kgnx-pyeUDKu"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MLP(modlee.model.TabularClassificationModleeModel):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super().__init__()\n",
        "        # Define the layers of the MLP model\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)  # Forward pass through the MLP\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        embeddings, labels = batch\n",
        "        logits = self.forward(embeddings)  # Forward pass\n",
        "        loss = self.loss_fn(logits, labels)  # Compute loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        embeddings, labels = batch\n",
        "        logits = self.forward(embeddings)  # Forward pass\n",
        "        loss = self.loss_fn(logits, labels)  # Compute validation loss\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUo6mJHlnRU3"
      },
      "source": [
        "## Step 8: Defining the Number of Classes and Initializing the MLP Model\n",
        "\n",
        "After defining the structure of the MLP model, the next step is to specify the number of output classes, which corresponds to the number of unique labels in our dataset.\n",
        "\n",
        "In the `CIFAR-10` dataset, there are 10 different classes, each representing a distinct object.\n",
        "\n",
        "\n",
        "\n",
        "We then initialize our MLP model by passing the input_size of the embeddings produced by `ResNet-50` and the `num_classes` for classification. This model will map the 2048-dimensional embeddings to the 10 class labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7yB5-MMfUE4O"
      },
      "outputs": [],
      "source": [
        "# Define the number of output classes for the classification task\n",
        "num_classes = 10\n",
        "\n",
        "# Initialize the MLP model with the specified input size and number of classes\n",
        "mlp_image = MLP(input_size=2048, num_classes=num_classes).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfr5gVkwaE4u"
      },
      "source": [
        "## Step 9: Precomputing Image Embeddings Using ResNet-50\n",
        "\n",
        "`ResNet-50` transforms images into numerical embeddings that can be fed into our model. First, we pass the raw images through the pre-trained `ResNet-50` model, which extracts high-level features from each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fFQKeztTmsEZ"
      },
      "outputs": [],
      "source": [
        "# Precompute embeddings using ResNet-50\n",
        "def precompute_embeddings(dataloader, model, device):\n",
        "    model.eval()\n",
        "    embeddings_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            embeddings = model(images).squeeze()  # Extract features using ResNet\n",
        "            embeddings_list.append(embeddings)\n",
        "            labels_list.append(labels)\n",
        "\n",
        "    return torch.cat(embeddings_list), torch.cat(labels_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPBYDeB-aE_y",
        "outputId": "2500c74b-54fc-4fdf-a370-a606f9534028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precomputing embeddings for training and validation data\n"
          ]
        }
      ],
      "source": [
        "# Precompute embeddings for training and validation datasets\n",
        "print(\"Precomputing embeddings for training and validation data\")\n",
        "train_embeddings, train_labels = precompute_embeddings(train_loader, resnet, device)\n",
        "val_embeddings, val_labels = precompute_embeddings(val_loader, resnet, device)\n",
        "\n",
        "# Create TensorDataset for precomputed embeddings and labels\n",
        "train_embedding_dataset = TensorDataset(train_embeddings, train_labels)\n",
        "val_embedding_dataset = TensorDataset(val_embeddings, val_labels)\n",
        "\n",
        "# Create DataLoaders for the precomputed embeddings\n",
        "train_embedding_loader = DataLoader(train_embedding_dataset, batch_size=64, shuffle=True)\n",
        "val_embedding_loader = DataLoader(val_embedding_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADJaOwPaoGdf"
      },
      "source": [
        "## Step 10: Training the Model\n",
        "We define the `train_model` function, which handles the training loop. The model uses `Cross-Entropy Loss` as the loss function and the `Adam optimizer` for weight updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BM1MhgA-UGQI"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloader, num_epochs=1):\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for embeddings, labels in dataloader:\n",
        "            embeddings = embeddings.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass through the MLP model\n",
        "            outputs = model(embeddings)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Perform backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Print average loss and accuracy for the epoch\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}, Accuracy: {100 * correct / total:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J7Wl97Homr6"
      },
      "source": [
        "## Step 11: Evaluating the Model\n",
        "Finally, we define an `evaluate_model` function to evaluate the model's performance on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uIfBvmHuoK9t"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for embeddings, labels in dataloader:\n",
        "            embeddings = embeddings.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass through the MLP model\n",
        "            outputs = model(embeddings)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Print the accuracy of the model on the dataset\n",
        "        print(f'Accuracy: {100 * correct / total:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD6j3ywHotUc"
      },
      "source": [
        "## Step 12: Training and Evaluating the Model\n",
        "\n",
        "After defining the model architecture and setting up the data loaders, the final step involves training the model on the training dataset and evaluating its performance on the validation set. This is done by calling two main functions: `train_model()` and `evaluate_model()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu-6eSKJoNMT",
        "outputId": "66fc1393-e215-403c-8a1e-7e3deb6adf73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Loss: 2.2100, Accuracy: 18.88%\n",
            "Epoch [2/5], Loss: 1.8648, Accuracy: 45.00%\n",
            "Epoch [3/5], Loss: 1.6762, Accuracy: 58.62%\n",
            "Epoch [4/5], Loss: 1.5282, Accuracy: 66.38%\n",
            "Epoch [5/5], Loss: 1.4218, Accuracy: 70.88%\n",
            "Accuracy: 66.50%\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate the model\n",
        "train_model(mlp_image, train_embedding_loader, num_epochs=5)\n",
        "evaluate_model(mlp_image, val_embedding_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALBrIAAIpOgm"
      },
      "source": [
        "# **Great Job!**\n",
        "\n",
        "We've successfully completed a machine learning project focused on image classification using a combination of ResNet-50 and a custom MLP. Here’s a quick recap of what we accomplished:\n",
        "\n",
        "- Loaded and prepared the CIFAR-10 dataset.\n",
        "- Feature extraction with ResNet-50.\n",
        "- Built and trained a custom MLP.\n",
        "- Evaluated the model.\n",
        "\n",
        "This project has given you a solid understanding of combining pre-trained models with custom architectures for classification tasks. With this knowledge, you're well-equipped to experiment with other datasets, adjust model architectures, and further improve your machine learning skills. Keep exploring and building on this foundation!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
