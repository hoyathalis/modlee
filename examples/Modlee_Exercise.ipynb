{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2_imh5L-AZU"
      },
      "source": [
        "# **Modlee Exercise**\n",
        "\n",
        "In this exercise, we will be assesing your ability to define a custom neural network for optimizing performance on a dataset.\n",
        "\n",
        "You will use the `modlee` package to:\n",
        "- Obtain your interview dataset and solution requirements\n",
        "- Define custom neural networks (~10)\n",
        "- Use Modlee to train neural networks and preserve your experimentation\n",
        "- Submit trained neural networks for evaluation\n",
        "\n",
        "## Expectations\n",
        "\n",
        "- Candidates typically experiment with at least **10** different model architectures during this exercise: defining the model, training, and submitting for evaluation\n",
        "\n",
        "## Tips\n",
        "\n",
        "For best performance, ensure that the runtime is set to use a GPU (`Runtime > Change runtime type > T4 GPU`).\n",
        "\n",
        "## Help & Questions\n",
        "\n",
        "If you have any questions about the interview, please reachout on our [Discord](https://discord.gg/dncQwFdN9m) #help-exercise channel.\n",
        "\n",
        "You can also use our [documenation](https://docs.modlee.ai/README.html) as a reference for using our package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jgwRjUiuy92p"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install modlee torch torchvision pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPjMKXvr-D5k"
      },
      "source": [
        "# **Environment setup**\n",
        "\n",
        "## Step 1\n",
        "We need to install `modlee` and its related packages.\n",
        "Make sure that you have a Modlee account and API key [from the dashboard](https://www.dashboard.modlee.ai/).\n",
        "\n",
        "**NOTE: if you are completing a Modlee Screening Exercise for a job interview, make sure that you sign up for a Modlee Account with the same email that your invite was sent to.**\n",
        "\n",
        "\n",
        "Replace `\"replace-with-your-api-key\"` with your API key.\n",
        "Run the following two cells; they will execute successively.\n",
        "This process may take a few minutes, so you can [review the examples](https://docs.modlee.ai/notebooks/document.html) while waiting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iGCBEIpWzDTX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Set your API key\n",
        "import os\n",
        "#simulate setting environment variable\n",
        "os.environ['MODLEE_API_KEY'] = \"GZ4a6OoXmCXUHDJGnnGWNofsPrK0YF0i\"\n",
        "api_key = os.environ['MODLEE_API_KEY']\n",
        "assert api_key != \"replace-with-your-api-key\", \"Please update the placeholder for your Modlee API key. See above Installation instructions.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hl2D5mF-LKU"
      },
      "source": [
        "## Step 2\n",
        "Time to import our packages for this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx7Xuq7--GEs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HCXp3h2BzHDh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tarushsingh/Desktop/work/Python/Modlee/modlee_pypi/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os,zipfile,shutil,requests\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.jit as jit\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import lightning.pytorch as pl\n",
        "import modlee\n",
        "from modlee.recommender import from_modality_task as trainer_for_modality_task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivsRWOVF-Nr5"
      },
      "source": [
        "# **Exercise setup**\n",
        "\n",
        "Please update `exercise_id`, `exercise_modality`, and `exercise_task` below.\n",
        "\n",
        "If you are completing a Screening Exercise for an organization please copy the `exercise_id`, `exercise_modality`, and `exercise_task` given to you in your invite email and paste below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aMeM5sqKzJYI"
      },
      "outputs": [],
      "source": [
        "exercise_id = 'TS-M4_GM_A_E_H__323565277395'\n",
        "exercise_modality = 'time_series'\n",
        "exercise_task = 'prediction'\n",
        "model_size_restriction_MB = '10'\n",
        "\n",
        "assert exercise_id != \"replace-with-your-exercise-id\", \"Please update the placeholder for your Modlee Exercise ID. See above Installation instructions.\"\n",
        "assert exercise_modality != \"replace-with-your-modality\", \"Please update the placeholder for your Modlee Exercise ID. See above Installation instructions.\"\n",
        "assert exercise_task != \"replace-with-your-exercise-task\", \"Please update the placeholder for your Modlee Exercise Task. See above Installation instructions.\"\n",
        "assert model_size_restriction_MB != \"replace-with-your-model_size_restriction_MB\", \"Please update the placeholder for your Modlee Exercise model_size_restriction_MB. See above Installation instructions.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfRGF8n-WVU"
      },
      "source": [
        "# **Dataset setup**\n",
        "\n",
        "**Please do not make changes to the following cell**\n",
        "\n",
        "For the machine learning interview exercise, the dataset has already been prepared for you. Please utilize the provided code snippet below to configure your environment appropriately. This dataset is a carefully curated blend of publicly available datasets, designed to assess specific competencies in model development and performance evaluation. As the focus of this exercise is not on data manipulation, you are requested not to make any modifications to the dataloader settings. This ensures that you can direct your efforts towards strategic model building and analysis tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WZ4HZFgVzW2I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File downloaded and saved as interview_utils.py\n",
            "File downloaded successfully: ./modlee_interview_data/modlee_interview_data.zip\n"
          ]
        }
      ],
      "source": [
        "root_url = 'https://evalserver.modlee.ai:6060'\n",
        "url = f\"{root_url}/get-interview-utils\"  # Change the port if your Flask app is running on a different one\n",
        "response = requests.get(url, params={'api_key': api_key,'exercise_id':exercise_id})\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    with open('interview_utils.py', 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "    print(\"File downloaded and saved as interview_utils.py\")\n",
        "else:\n",
        "    print(\"Failed to download file:\", response.status_code)\n",
        "\n",
        "from interview_utils import *\n",
        "from interview_utils import setup,submit\n",
        "\n",
        "train_dataloader, val_dataloader, train_dataloader_shape, val_dataloader_shape = setup(api_key,exercise_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wGtq6M8PKnuV"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY\n",
        "input_size = train_dataloader_shape[2]\n",
        "output_size = train_dataloader_shape[2]\n",
        "output_seq_len = val_dataloader_shape[1]  # 7 time steps for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug4VAX96-crj"
      },
      "source": [
        "# **Define your models**\n",
        "\n",
        "**Critical segment of your machine learning interview**\n",
        "\n",
        "Please define and experiment with various deep neural network architectures. Your task is to identify and implement a model structure that will perform optimally on the provided interview dataset. It is essential that your model design adheres to the specified solution requirements previously stated. This exercise aims to showcase your ability to innovate and apply your ML knowledge effectively in developing custom neural network based solutions.\n",
        "\n",
        "Please follow our [Custom Model Definition Guidelines](https://docs.modlee.ai/notebooks/model_definition_guidelines.html) throughout your experimentation to ensure your submitions are evaluated properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "db91YLlGKua5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n-------------------------------------------------\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "------------------------------------------------\n",
        "TODO: Make Changes Here\n",
        "------------------------------------------------\n",
        "   ExampleLSTM is defined just to get you started.\n",
        "   Please experiment with many models searching for the best.\n",
        "   We recommend experimenting with at least 10 different models in this exercise.\n",
        "'''\n",
        "\n",
        "class ExampleLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, output_seq_len):\n",
        "        super(ExampleLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.output_seq_len = output_seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len, input_size] where seq_len=10\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        # Initialize an empty list to store the outputs for each of the 5 future time steps\n",
        "        out = []\n",
        "        # Use the hidden state from the last time step to predict each future time step\n",
        "        for t in range(self.output_seq_len):\n",
        "            out_step = self.fc(lstm_out[:, -1, :])  # Use the last hidden state to predict each step\n",
        "            out.append(out_step.unsqueeze(1))\n",
        "\n",
        "        out = torch.cat(out, dim=1)  # Concatenate all time steps to form the output sequence\n",
        "        return out\n",
        "\n",
        "\n",
        "'''\n",
        "-------------------------------------------------\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aJot7IG_J23"
      },
      "source": [
        "# **Train your models**\n",
        "\n",
        "**Please do not make changes to the following cell**\n",
        "\n",
        "In this phase of your machine learning interview exercise, you are tasked with training your previously defined model using Modlee's advanced training infrastructure. Our trainers, specifically the trainer_for_modality_task instances, are equipped with robust out-of-the-box training features such as learning rate decay, early stopping, and more. Please utilize these settings to train your model. This approach is not only designed to streamline the training process but also allows us to assess your proficiency in optimizing and refining deep learning models through architectural adjustments. This step is crucial in demonstrating your ability to enhance model performance within given constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CpjmOptyKY-t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Step [100/105], Loss: 0.5550\n",
            "Epoch [1/100], Val Loss: 2.9454\n",
            "Epoch [2/100], Step [100/105], Loss: 0.4752\n",
            "Epoch [2/100], Val Loss: 2.6373\n",
            "Epoch [3/100], Step [100/105], Loss: 0.3340\n",
            "Epoch [3/100], Val Loss: 2.5580\n",
            "Epoch [4/100], Step [100/105], Loss: 0.2816\n",
            "Epoch [4/100], Val Loss: 2.3125\n",
            "Epoch [5/100], Step [100/105], Loss: 0.2822\n",
            "Epoch [5/100], Val Loss: 2.2786\n",
            "Epoch [6/100], Step [100/105], Loss: 0.3097\n",
            "Epoch [6/100], Val Loss: 2.3103\n",
            "Epoch [7/100], Step [100/105], Loss: 0.3074\n",
            "Epoch [7/100], Val Loss: 2.5317\n",
            "Epoch [8/100], Step [100/105], Loss: 0.2729\n",
            "Epoch [8/100], Val Loss: 2.6105\n",
            "Epoch [9/100], Step [100/105], Loss: 0.2711\n",
            "Epoch [9/100], Val Loss: 2.6285\n",
            "Epoch [10/100], Step [100/105], Loss: 0.2772\n",
            "Epoch [10/100], Val Loss: 2.6405\n",
            "Epoch [11/100], Step [100/105], Loss: 0.2452\n",
            "Epoch [11/100], Val Loss: 2.7388\n",
            "Epoch [12/100], Step [100/105], Loss: 0.2896\n",
            "Epoch [12/100], Val Loss: 2.7312\n",
            "Epoch [13/100], Step [100/105], Loss: 0.2271\n",
            "Epoch [13/100], Val Loss: 2.7014\n",
            "Epoch [14/100], Step [100/105], Loss: 0.2480\n",
            "Epoch [14/100], Val Loss: 2.6967\n",
            "Epoch [15/100], Step [100/105], Loss: 0.2435\n",
            "Epoch [15/100], Val Loss: 2.7675\n",
            "Epoch [16/100], Step [100/105], Loss: 0.2585\n",
            "Epoch [16/100], Val Loss: 2.7752\n",
            "Epoch [17/100], Step [100/105], Loss: 0.1967\n",
            "Epoch [17/100], Val Loss: 2.8271\n",
            "Epoch [18/100], Step [100/105], Loss: 0.2871\n",
            "Epoch [18/100], Val Loss: 2.8210\n",
            "Epoch [19/100], Step [100/105], Loss: 0.2446\n",
            "Epoch [19/100], Val Loss: 2.7889\n",
            "Epoch [20/100], Step [100/105], Loss: 0.2468\n",
            "Epoch [20/100], Val Loss: 2.8230\n",
            "Epoch [21/100], Step [100/105], Loss: 0.2217\n",
            "Epoch [21/100], Val Loss: 2.8947\n",
            "Epoch [22/100], Step [100/105], Loss: 0.2478\n",
            "Epoch [22/100], Val Loss: 2.8540\n",
            "Epoch [23/100], Step [100/105], Loss: 0.1834\n",
            "Epoch [23/100], Val Loss: 2.8605\n",
            "Epoch [24/100], Step [100/105], Loss: 0.2072\n",
            "Epoch [24/100], Val Loss: 2.9674\n",
            "Epoch [25/100], Step [100/105], Loss: 0.2195\n",
            "Epoch [25/100], Val Loss: 2.9576\n",
            "Epoch [26/100], Step [100/105], Loss: 0.1978\n",
            "Epoch [26/100], Val Loss: 2.9416\n",
            "Epoch [27/100], Step [100/105], Loss: 0.2229\n",
            "Epoch [27/100], Val Loss: 3.0165\n",
            "Epoch [28/100], Step [100/105], Loss: 0.1985\n",
            "Epoch [28/100], Val Loss: 2.9364\n",
            "Epoch [29/100], Step [100/105], Loss: 0.2005\n",
            "Epoch [29/100], Val Loss: 2.8886\n",
            "Epoch [30/100], Step [100/105], Loss: 0.2291\n",
            "Epoch [30/100], Val Loss: 2.9716\n",
            "Epoch [31/100], Step [100/105], Loss: 0.2135\n",
            "Epoch [31/100], Val Loss: 3.0643\n",
            "Epoch [32/100], Step [100/105], Loss: 0.1961\n",
            "Epoch [32/100], Val Loss: 3.0557\n",
            "Epoch [33/100], Step [100/105], Loss: 0.2152\n",
            "Epoch [33/100], Val Loss: 3.0090\n",
            "Epoch [34/100], Step [100/105], Loss: 0.2292\n",
            "Epoch [34/100], Val Loss: 2.9589\n",
            "Epoch [35/100], Step [100/105], Loss: 0.1944\n",
            "Epoch [35/100], Val Loss: 3.0709\n",
            "Epoch [36/100], Step [100/105], Loss: 0.1860\n",
            "Epoch [36/100], Val Loss: 3.0415\n",
            "Epoch [37/100], Step [100/105], Loss: 0.1790\n",
            "Epoch [37/100], Val Loss: 3.0340\n",
            "Epoch [38/100], Step [100/105], Loss: 0.2028\n",
            "Epoch [38/100], Val Loss: 2.9581\n",
            "Epoch [39/100], Step [100/105], Loss: 0.2544\n",
            "Epoch [39/100], Val Loss: 2.9778\n",
            "Epoch [40/100], Step [100/105], Loss: 0.2133\n",
            "Epoch [40/100], Val Loss: 3.0251\n",
            "Epoch [41/100], Step [100/105], Loss: 0.2286\n",
            "Epoch [41/100], Val Loss: 3.0224\n",
            "Epoch [42/100], Step [100/105], Loss: 0.2776\n",
            "Epoch [42/100], Val Loss: 3.0671\n",
            "Epoch [43/100], Step [100/105], Loss: 0.2283\n",
            "Epoch [43/100], Val Loss: 3.0078\n",
            "Epoch [44/100], Step [100/105], Loss: 0.2175\n",
            "Epoch [44/100], Val Loss: 2.9865\n",
            "Epoch [45/100], Step [100/105], Loss: 0.2282\n",
            "Epoch [45/100], Val Loss: 3.0143\n",
            "Epoch [46/100], Step [100/105], Loss: 0.1744\n",
            "Epoch [46/100], Val Loss: 3.0430\n",
            "Epoch [47/100], Step [100/105], Loss: 0.2246\n",
            "Epoch [47/100], Val Loss: 3.0490\n",
            "Epoch [48/100], Step [100/105], Loss: 0.2155\n",
            "Epoch [48/100], Val Loss: 3.0196\n",
            "Epoch [49/100], Step [100/105], Loss: 0.2282\n",
            "Epoch [49/100], Val Loss: 3.0399\n",
            "Epoch [50/100], Step [100/105], Loss: 0.2742\n",
            "Epoch [50/100], Val Loss: 3.0428\n",
            "Epoch [51/100], Step [100/105], Loss: 0.2597\n",
            "Epoch [51/100], Val Loss: 3.0952\n",
            "Epoch [52/100], Step [100/105], Loss: 0.2356\n",
            "Epoch [52/100], Val Loss: 3.0977\n",
            "Epoch [53/100], Step [100/105], Loss: 0.2149\n",
            "Epoch [53/100], Val Loss: 3.0633\n",
            "Epoch [54/100], Step [100/105], Loss: 0.2004\n",
            "Epoch [54/100], Val Loss: 3.0569\n",
            "Epoch [55/100], Step [100/105], Loss: 0.2017\n",
            "Epoch [55/100], Val Loss: 3.1382\n",
            "Epoch [56/100], Step [100/105], Loss: 0.2279\n",
            "Epoch [56/100], Val Loss: 3.1224\n",
            "Epoch [57/100], Step [100/105], Loss: 0.1634\n",
            "Epoch [57/100], Val Loss: 3.1832\n",
            "Epoch [58/100], Step [100/105], Loss: 0.1819\n",
            "Epoch [58/100], Val Loss: 3.0691\n",
            "Epoch [59/100], Step [100/105], Loss: 0.2077\n",
            "Epoch [59/100], Val Loss: 3.0989\n",
            "Epoch [60/100], Step [100/105], Loss: 0.2611\n",
            "Epoch [60/100], Val Loss: 3.1244\n",
            "Epoch [61/100], Step [100/105], Loss: 0.2280\n",
            "Epoch [61/100], Val Loss: 3.1470\n",
            "Epoch [62/100], Step [100/105], Loss: 0.2210\n",
            "Epoch [62/100], Val Loss: 3.1471\n",
            "Epoch [63/100], Step [100/105], Loss: 0.1612\n",
            "Epoch [63/100], Val Loss: 3.1180\n",
            "Epoch [64/100], Step [100/105], Loss: 0.1810\n",
            "Epoch [64/100], Val Loss: 3.1014\n",
            "Epoch [65/100], Step [100/105], Loss: 0.2091\n",
            "Epoch [65/100], Val Loss: 3.1247\n",
            "Epoch [66/100], Step [100/105], Loss: 0.2179\n",
            "Epoch [66/100], Val Loss: 3.1365\n",
            "Epoch [67/100], Step [100/105], Loss: 0.1915\n",
            "Epoch [67/100], Val Loss: 3.1776\n",
            "Epoch [68/100], Step [100/105], Loss: 0.1709\n",
            "Epoch [68/100], Val Loss: 3.1189\n",
            "Epoch [69/100], Step [100/105], Loss: 0.2128\n",
            "Epoch [69/100], Val Loss: 3.1786\n",
            "Epoch [70/100], Step [100/105], Loss: 0.2307\n",
            "Epoch [70/100], Val Loss: 3.1153\n",
            "Epoch [71/100], Step [100/105], Loss: 0.2230\n",
            "Epoch [71/100], Val Loss: 3.0782\n",
            "Epoch [72/100], Step [100/105], Loss: 0.2456\n",
            "Epoch [72/100], Val Loss: 3.1329\n",
            "Epoch [73/100], Step [100/105], Loss: 0.2187\n",
            "Epoch [73/100], Val Loss: 3.0342\n",
            "Epoch [74/100], Step [100/105], Loss: 0.1891\n",
            "Epoch [74/100], Val Loss: 3.1082\n",
            "Epoch [75/100], Step [100/105], Loss: 0.2005\n",
            "Epoch [75/100], Val Loss: 3.0965\n",
            "Epoch [76/100], Step [100/105], Loss: 0.1799\n",
            "Epoch [76/100], Val Loss: 3.1355\n",
            "Epoch [77/100], Step [100/105], Loss: 0.2688\n",
            "Epoch [77/100], Val Loss: 3.0981\n",
            "Epoch [78/100], Step [100/105], Loss: 0.2098\n",
            "Epoch [78/100], Val Loss: 3.1766\n",
            "Epoch [79/100], Step [100/105], Loss: 0.2357\n",
            "Epoch [79/100], Val Loss: 3.0939\n",
            "Epoch [80/100], Step [100/105], Loss: 0.1836\n",
            "Epoch [80/100], Val Loss: 3.1668\n",
            "Epoch [81/100], Step [100/105], Loss: 0.1851\n",
            "Epoch [81/100], Val Loss: 3.0961\n",
            "Epoch [82/100], Step [100/105], Loss: 0.2273\n",
            "Epoch [82/100], Val Loss: 3.1469\n",
            "Epoch [83/100], Step [100/105], Loss: 0.1792\n",
            "Epoch [83/100], Val Loss: 3.1658\n",
            "Epoch [84/100], Step [100/105], Loss: 0.2357\n",
            "Epoch [84/100], Val Loss: 3.1158\n",
            "Epoch [85/100], Step [100/105], Loss: 0.2358\n",
            "Epoch [85/100], Val Loss: 3.1836\n",
            "Epoch [86/100], Step [100/105], Loss: 0.2012\n",
            "Epoch [86/100], Val Loss: 3.1276\n",
            "Epoch [87/100], Step [100/105], Loss: 0.2197\n",
            "Epoch [87/100], Val Loss: 3.1249\n",
            "Epoch [88/100], Step [100/105], Loss: 0.2392\n",
            "Epoch [88/100], Val Loss: 3.1583\n",
            "Epoch [89/100], Step [100/105], Loss: 0.2356\n",
            "Epoch [89/100], Val Loss: 3.1232\n",
            "Epoch [90/100], Step [100/105], Loss: 0.2009\n",
            "Epoch [90/100], Val Loss: 3.2113\n",
            "Epoch [91/100], Step [100/105], Loss: 0.2516\n",
            "Epoch [91/100], Val Loss: 3.1574\n",
            "Epoch [92/100], Step [100/105], Loss: 0.1560\n",
            "Epoch [92/100], Val Loss: 3.1261\n",
            "Epoch [93/100], Step [100/105], Loss: 0.1669\n",
            "Epoch [93/100], Val Loss: 3.1279\n",
            "Epoch [94/100], Step [100/105], Loss: 0.2275\n",
            "Epoch [94/100], Val Loss: 3.1300\n",
            "Epoch [95/100], Step [100/105], Loss: 0.1971\n",
            "Epoch [95/100], Val Loss: 3.1420\n",
            "Epoch [96/100], Step [100/105], Loss: 0.1913\n",
            "Epoch [96/100], Val Loss: 3.1417\n",
            "Epoch [97/100], Step [100/105], Loss: 0.2140\n",
            "Epoch [97/100], Val Loss: 3.1123\n",
            "Epoch [98/100], Step [100/105], Loss: 0.2357\n",
            "Epoch [98/100], Val Loss: 3.1433\n",
            "Epoch [99/100], Step [100/105], Loss: 0.1988\n",
            "Epoch [99/100], Val Loss: 3.1658\n",
            "Epoch [100/100], Step [100/105], Loss: 0.2057\n",
            "Epoch [100/100], Val Loss: 3.1937\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "  ------------------------------------------------\n",
        "  TODO: Make Changes Here\n",
        "  ------------------------------------------------\n",
        "  Define parameters, training loop validation step\n",
        "\n",
        "'''\n",
        "\n",
        "# JUST FOR CONTEXT - Since this is not supported in the package just yet,\n",
        "# we need to train manually, when it is supported, we will train like this\n",
        "\n",
        "\"\"\"\n",
        "      modlee.mlflow.end_run()\n",
        "\n",
        "      trainer = trainer_for_modality_task(\n",
        "          modality=exercise_modality,\n",
        "          task=exercise_task,\n",
        "          )\n",
        "\n",
        "      trainer.dataloader = unzip_train_dataloader\n",
        "      trainer.model = modlee_model\n",
        "\n",
        "      trainer.train(max_epochs=10, val_dataloaders=unzip_val_dataloader)\n",
        "\"\"\"\n",
        "\n",
        "# Define parameters\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create an instance of the model\n",
        "model = ExampleLSTM(input_size, hidden_size, num_layers, output_size, output_seq_len)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training Loop\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, targets) in enumerate(train_dataloader):\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_dataloader:\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, targets)\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Val Loss: {val_loss.item():.4f}')\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g_ACcV2_OdF"
      },
      "source": [
        "# **Evaluate your models**\n",
        "\n",
        "**Please do not make changes to the following cell**\n",
        "\n",
        "\n",
        "Please submit your model experiment to Modlee for evaluation. We will provide you with detailed feedback including accuracy, model size, and additional metrics. Keep in mind that **there are no penalties for submitting suboptimal solutions**, so feel free to submit multiple models as needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qg4TxDdfKZBv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Request was successful.\n",
            "Response: {'mean_square_error': '1.0811', 'model_size (MB)': '0.26', 'submission_id': 'TS-E-2024-08-25T19:24:48.179727_70738853129'}\n",
            "As a reminder, your exercises model_size_restriction_MB is  10\n"
          ]
        }
      ],
      "source": [
        "submit(api_key,exercise_id,model,None,modlee)\n",
        "print('As a reminder, your exercises model_size_restriction_MB is ',model_size_restriction_MB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUUC7zNh_SEY"
      },
      "source": [
        "# **Great work, now keep exploring more models!**\n",
        "\n",
        "Use the insights gained from each evaluation to iteratively refine your model's architecture. This process is designed to help you optimize your solution effectively, utilizing real-world feedback to enhance your approach.\n",
        "\n",
        "## Solution Requirements\n",
        "\n",
        "- Maximize evaluation accuracy\n",
        "- Ensure your models don't go over model size restrictions\n",
        "\n",
        "## Expectations\n",
        "\n",
        "- Candidates typically experiment with at least **10** different model architectures during this exercise: defining the model, training, and submitting for evaluation\n",
        "\n",
        "## Evaluating your performance\n",
        "\n",
        "- We want to see your experimenation process so just work as you normally would\n",
        "- We will take your best model as your final submission, and do not penalize sub-optimal submissions. Feel free to submit as many models as you want to for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O-mdL3G_S8b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
