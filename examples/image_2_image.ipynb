{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/mansiagr4/gifs/raw/main/new_small_logo.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image2Image Example\n",
    "\n",
    "In this tutorial, we will walk through the process of building a deep learning model using the Modlee package and PyTorch to denoise images from the CIFAR-10 dataset. \n",
    "\n",
    "The objective is to train a model that can learn to remove noise from images, which is a common task in image processing. \n",
    "\n",
    "[![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/modlee/image2image)\n",
    "\n",
    "First, we will import the the necessary libraries and set up the environment. \n",
    "```python\n",
    "import torch\n",
    "import os\n",
    "import modlee\n",
    "import lightning.pytorch as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "from utils import check_artifacts\n",
    "\n",
    "```\n",
    "Now, we will set up the `modlee` API key and initialize the `modlee` package. You can access your `modlee` API key [from the dashboard](https://www.dashboard.modlee.ai/).\n",
    "\n",
    "Replace `replace-with-your-api-key` with your API key.\n",
    "```python\n",
    "modlee.init(api_key=\"replace-with-your-api-key\")\n",
    "```\n",
    "\n",
    "To train our denoising model, we need to simulate noisy images. This is done using a function called `add_noise`, which takes an image and a noise level as inputs. \n",
    "\n",
    "We generate random noise and add it to the original image, ensuring that the pixel values remain within the valid range of `[0, 1]`.\n",
    "\n",
    "```python\n",
    "def add_noise(img, noise_level=0.1):\n",
    "    # Generate random noise with the specified noise level\n",
    "    noise = torch.randn_like(img) * noise_level\n",
    "    # Add noise to the original image and clamp the values to stay in range [0, 1]\n",
    "    return torch.clamp(img + noise, 0., 1.)\n",
    "```\n",
    "\n",
    "We define a custom dataset class called `NoisyImageDataset`, which inherits from `torch.utils.data.Dataset`. This class will help us create a dataset that contains noisy images along with their clean counterparts. \n",
    "\n",
    "```python\n",
    "class NoisyImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, noise_level=0.1, img_size=(1, 32, 32)):\n",
    "        self.dataset = dataset  # Store the original dataset\n",
    "        self.noise_level = noise_level  # Store the noise level\n",
    "        self.img_size = img_size  # Store the target image size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)  # Return the size of the dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.dataset[idx]  # Retrieve the image and ignore the label\n",
    "        \n",
    "        # Resize the image if necessary\n",
    "        if img.size(0) != self.img_size[0]:\n",
    "            if img.size(0) < self.img_size[0]:  \n",
    "                img = img.repeat(self.img_size[0] // img.size(0), 1, 1)  # Repeat channels to match size\n",
    "            else:  \n",
    "                img = img[:self.img_size[0], :, :]  # Crop channels to match size\n",
    "\n",
    "        # Resize the image to the target size\n",
    "        img = transforms.Resize((self.img_size[1], self.img_size[2]))(img)  \n",
    "        noisy_img = add_noise(img, self.noise_level)  # Create a noisy version of the image\n",
    "        return noisy_img, img  # Return the noisy image and the clean image\n",
    "```\n",
    "\n",
    "Next, we create a model class called `ModleeDenoisingModel`, which extends `modlee.model.ImageImageToImageModleeModel`. This class defines the architecture of our neural network, which consists of convolutional layers for feature extraction. \n",
    "\n",
    "```python\n",
    "class ModleeDenoisingModel(modlee.model.ImageImageToImageModleeModel):\n",
    "    def __init__(self, img_size=(1, 32, 32)):\n",
    "        super().__init__()  # Initialize the parent class\n",
    "        self.img_size = img_size  # Store the image size\n",
    "        in_channels = img_size[0]  # Get the number of input channels\n",
    "        # Define the model architecture\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, kernel_size=3, stride=1, padding=1),  # First convolutional layer\n",
    "            nn.ReLU(),  # Activation function\n",
    "            nn.Conv2d(16, in_channels, kernel_size=3, stride=1, padding=1)  # Second convolutional layer\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()  # Define the loss function as Mean Squared Error\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Define the forward pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch  # Get the noisy images and their clean counterparts\n",
    "        y_pred = self.forward(x)  # Get the model predictions\n",
    "        loss = self.loss_fn(y_pred, y)  # Calculate the loss\n",
    "        return {'loss': loss}  # Return the loss value\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y_target = val_batch  # Get the validation batch\n",
    "        y_pred = self.forward(x)  # Get the model predictions\n",
    "        val_loss = self.loss_fn(y_pred, y_target)  # Calculate validation loss\n",
    "        return {'val_loss': val_loss}  # Return the validation loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=1e-3)  # Set up the optimizer\n",
    "```\n",
    "\n",
    "Now we need to create our datasets. We will use the `CIFAR-10` dataset, which consists of 60,000 32x32 color images in 10 different classes. \n",
    "\n",
    "To make our dataset suitable for training, we first define the transformations to be applied to the images, which includes resizing and converting them to tensors. We create both training and testing datasets, applying our `NoisyImageDataset` class to introduce noise.\n",
    "\n",
    "```python\n",
    "noise_level = 0.1  # Define the level of noise to add\n",
    "img_size = (3, 32, 32)  # Define the target image size (channels, height, width)\n",
    "\n",
    "# Define the transformations to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size[1], img_size[2])),  # Resize images to the target size\n",
    "    transforms.ToTensor()  # Convert images to tensor format\n",
    "])\n",
    "\n",
    "# Download and load the CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Create noisy datasets for training and testing\n",
    "train_noisy_dataset = NoisyImageDataset(train_dataset, noise_level=noise_level, img_size=img_size)\n",
    "test_noisy_dataset = NoisyImageDataset(test_dataset, noise_level=noise_level, img_size=img_size)\n",
    "```\n",
    "\n",
    "We then create `DataLoader` objects for both training and testing datasets to enable batch processing during training.\n",
    "\n",
    "```python\n",
    "# Create DataLoader for training and testing datasets\n",
    "train_dataloader = DataLoader(train_noisy_dataset, batch_size=2, shuffle=True)  # Shuffle training data\n",
    "test_dataloader = DataLoader(test_noisy_dataset, batch_size=2, shuffle=False)  # Do not shuffle test data\n",
    "```\n",
    "\n",
    "Now that we have our model and data prepared, we can begin training. We instantiate the `ModleeDenoisingModel`. We start a training run using `modlee.start_run()`, which automatically logs the experiment details. \n",
    "\n",
    "```python\n",
    "model = ModleeDenoisingModel(img_size=img_size)  # Instantiate the model \n",
    "\n",
    "with modlee.start_run() as run:  # Start a training run\n",
    "    trainer = pl.Trainer(max_epochs=1)  # Set up the trainer\n",
    "    trainer.fit(  # Start training the model\n",
    "        model=model,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=test_dataloader  # Use test data for validation\n",
    "    )\n",
    "```\n",
    "\n",
    "After training, we inspect the artifacts saved by Modlee, including the model graph and various statistics. With Modlee, your training assets are automatically saved, preserving valuable insights for future reference and collaboration.\n",
    "\n",
    "```python\n",
    "last_run_path = modlee.last_run_path()\n",
    "print(f\"Run path: {last_run_path}\")\n",
    "artifacts_path = os.path.join(last_run_path, 'artifacts')\n",
    "artifacts = sorted(os.listdir(artifacts_path))\n",
    "print(f\"Saved artifacts: {artifacts}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
